{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here~!\n",
      "jams-f92b1.firebasestorage.app\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import requests\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, storage\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "def encode_image_to_base64(path):\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    return encoded_string\n",
    "\n",
    "if not firebase_admin._apps:\n",
    "    cred = credentials.Certificate(\"/home/ddddewang/Desktop/jams-f92b1-firebase-adminsdk-fbsvc-8651bbf671.json\")\n",
    "    firebase_admin.initialize_app(cred, {\n",
    "        'storageBucket': 'jams-f92b1.firebasestorage.app'\n",
    "    })\n",
    "else:\n",
    "    print(\"Here~!\")\n",
    "    app = firebase_admin.get_app()\n",
    "    print(app.options.get('storageBucket', 'No storage bucket found'))\n",
    "class ImageUploader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def upload_to_firebase(self, image_path, myuuid):\n",
    "        bucket = storage.bucket()\n",
    "        blob = bucket.blob(f\"uploads/{myuuid}/{uuid.uuid4()}{os.path.splitext(image_path)[1]}\")\n",
    "        blob.upload_from_filename(image_path)\n",
    "        blob.make_public()\n",
    "        return blob.public_url\n",
    "\n",
    "class LLMChatBot:\n",
    "    def __init__(self, model_name=\"gpt-4o\", temperature=0.4, key=None, uuid=None):\n",
    "        self.img_uploader = ImageUploader()\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.messages = []\n",
    "        assert key is not None, \"API key must be provided\"\n",
    "        assert uuid is not None, \"UUID must be provided\"\n",
    "        self.client = OpenAI(\n",
    "            api_key=key\n",
    "        )\n",
    "        self.uuid = uuid\n",
    "        print(\"LLMChatBot is initialized with model:\", self.model_name)\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def add_message_front(self, role, content):\n",
    "        if len(self.messages) == 0:\n",
    "            self.messages.append({\"role\": role, \"content\": content})\n",
    "        else:\n",
    "            self.messages.insert(0, {\"role\": role, \"content\": content})\n",
    "    \n",
    "    def pop_message(self):\n",
    "        if self.messages:\n",
    "            return self.messages.pop()\n",
    "        return None\n",
    "    \n",
    "    def pop_message_front(self):\n",
    "        if self.messages:\n",
    "            return self.messages.pop(0)\n",
    "        return None\n",
    "\n",
    "    def have_system_prompt(self):\n",
    "        if len(self.messages)>0:\n",
    "            return self.messages[0]['role'] == 'system'\n",
    "        return False\n",
    "    \n",
    "    def clear_messages(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def get_response(self, query, store=True):\n",
    "        if store:\n",
    "            self.add_message(\"user\",query)\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=self.messages,\n",
    "            temperature=self.temperature,\n",
    "        )\n",
    "        if store:\n",
    "            self.add_message(\"assistant\", response.choices[0].message.content)\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def get_response_vision(self, query, image_path, text_store=True, image_store=False):\n",
    "        image_url = self.img_uploader.upload_to_firebase(image_path, self.uuid)\n",
    "        # image_b64 = encode_image_to_base64(image_path)\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=self.messages[0:] + [{\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": query},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "                    ], \n",
    "                }], \n",
    "            temperature=self.temperature,\n",
    "        )\n",
    "        if image_store:\n",
    "            self.add_message(\"user\",[\n",
    "                        {\"type\": \"text\", \"text\": query},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "                    ])\n",
    "            self.add_message(\"assistant\", response.choices[0].message.content)\n",
    "        elif text_store:\n",
    "            self.add_message(\"user\", query)\n",
    "            self.add_message(\"assistant\", response.choices[0].message.content)\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "class ChefBot(LLMChatBot):\n",
    "    def __init__(self, model_name=\"gpt-4o\", temperature=0.4, key=None, uuid=None, system_prompt_path=\"ChefBotSystemPrompt.txt\"):\n",
    "        super().__init__(model_name, temperature, key, uuid)\n",
    "        self.init_system_prompt(system_prompt_path)\n",
    "\n",
    "    def init_system_prompt(self, system_prompt_path):\n",
    "        if self.have_system_prompt():\n",
    "            self.pop_message_front()\n",
    "        self.add_message_front(\"system\",open(system_prompt_path, \"r\").read())\n",
    "\n",
    "    def get_response_realtime_vision(self, query, image_path=\"vision.png\", text_store=True, image_store=False):\n",
    "        \"\"\"\n",
    "        The parameters:\n",
    "            - image_path: needed to be updated with the precise image name.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.get_response_vision(query, image_path, text_store, image_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9c63ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMChatBot is initialized with model: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "apikey = open(\"/home/ddddewang/Desktop/gptapi.txt\", \"r\").read().strip()\n",
    "myuuid = open(\"/home/ddddewang/Desktop/myuuid.txt\", \"r\").read().strip()\n",
    "MyBot = ChefBot(model_name=\"gpt-4o\", temperature=1.0, key=apikey, uuid=myuuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09428082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK에서 참조하는 실제 버킷 이름: jams-f92b1.firebasestorage.app\n",
      "죄송하지만 이미지를 분석하여 구체적인 재료를 식별할 수는 없습니다. 그러나 일반적인 예를 들어 JSON 형식으로 요리 레시피를 제공할 수 있습니다. 냉장고에 있는 일반적인 재료를 사용한 예시 JSON입니다:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"recipe\": {\n",
      "    \"name\": \"Simple Salad\",\n",
      "    \"ingredients\": [\n",
      "      \"lettuce\",\n",
      "      \"tomato\",\n",
      "      \"cucumber\",\n",
      "      \"cheese\",\n",
      "      \"boiled egg\",\n",
      "      \"olive oil\",\n",
      "      \"balsamic vinegar\"\n",
      "    ],\n",
      "    \"instructions\": [\n",
      "      \"Wash all vegetables thoroughly.\",\n",
      "      \"Slice the tomato and cucumber.\",\n",
      "      \"Dice the boiled egg.\",\n",
      "      \"Combine all ingredients in a large bowl.\",\n",
      "      \"Add sliced cheese on top.\",\n",
      "      \"Drizzle with olive oil and balsamic vinegar, then mix well.\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "이 형식을 따라 활용 가능한 다른 재료로 JSON 레시피를 만들어보세요!\n"
     ]
    }
   ],
   "source": [
    "print(MyBot.get_response_vision(\"너의 시스템 프롬프트상 요리 레시피는 어떤 포맷으로 출력되어야 하지? 그 플랫폼에 맞춰서 내가 보여준 냉장고 이미지 내부의 재료들로 만들 수 있는 요리 레시피를 알려줘. 참고로 너는 레시피를 json 형태로만 출력해야해.\", \"refrigerator_example.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "820eee36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"알리오 올리오\",\n",
      "  \"ingredients\": \"스파게티 면 200g, 올리브 오일 100ml, 마늘 6쪽, 페페론치노 2개, 소금 약간, 파슬리 약간\",\n",
      "  \"recipe\": [\n",
      "    \"1. 마늘은 얇게 슬라이스합니다.\",\n",
      "    \"2. 페페론치노는 반으로 쪼개거나 잘게 부숩니다.\",\n",
      "    \"3. 냄비에 물을 끓이고 소금을 넣은 뒤, 스파게티 면을 포장지에 적힌 시간보다 1분 짧게 삶습니다.\",\n",
      "    \"4. 면을 건져내어 물기를 빼고, 삶은 물을 한 컵 따로 보관합니다.\",\n",
      "    \"5. 팬에 올리브 오일을 두르고 중약불에서 마늘을 볶아 향을 냅니다.\",\n",
      "    \"6. 마늘이 약간 노릇해지면 페페론치노를 추가해 함께 볶습니다.\",\n",
      "    \"7. 삶은 스파게티 면을 팬에 넣고, 준비한 면수를 조금씩 추가하며 섞어줍니다.\",\n",
      "    \"8. 소금으로 간을 맞추고, 마지막으로 파슬리를 뿌려 섞습니다.\",\n",
      "    \"9. 완성된 알리오 올리오를 접시에 담아냅니다.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(MyBot.get_response(\"알리오 올리오 레시피 알려줘.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f49b782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버킷 이름: jams-f92b1.appspot.com\n"
     ]
    }
   ],
   "source": [
    "from firebase_admin import storage\n",
    "bucket = storage.bucket()\n",
    "print(\"버킷 이름:\", bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12823d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fortest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
