{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f7e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here~!\n",
      "jams-f92b1.firebasestorage.app\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import requests\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, storage\n",
    "import uuid\n",
    "import os\n",
    "import json\n",
    "import config\n",
    "def encode_image_to_base64(path):\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    return encoded_string\n",
    "if not firebase_admin._apps:\n",
    "    cred = credentials.Certificate(config.get_firebase())\n",
    "    firebase_admin.initialize_app(cred, {\n",
    "        'storageBucket': 'jams-f92b1.firebasestorage.app'\n",
    "    })\n",
    "else:\n",
    "    print(\"Here~!\")\n",
    "    app = firebase_admin.get_app()\n",
    "    print(app.options.get('storageBucket', 'No storage bucket found'))\n",
    "class ImageUploader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def upload_to_firebase(self, image_path, myuuid):\n",
    "        bucket = storage.bucket()\n",
    "        blob = bucket.blob(f\"uploads/{myuuid}/{uuid.uuid4()}{os.path.splitext(image_path)[1]}\")\n",
    "        blob.upload_from_filename(image_path)\n",
    "        blob.make_public()\n",
    "        return blob.public_url\n",
    "\n",
    "class LLMChatBot:\n",
    "    def __init__(self, model_name=\"gpt-4o\", temperature=0.4, key=None, uuid=None):\n",
    "        self.img_uploader = ImageUploader()\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.messages = []\n",
    "        assert key is not None, \"API key must be provided\"\n",
    "        assert uuid is not None, \"UUID must be provided\"\n",
    "        self.client = OpenAI(\n",
    "            api_key=key\n",
    "        )\n",
    "        self.uuid = uuid\n",
    "        print(\"LLMChatBot is initialized with model:\", self.model_name)\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def add_message_front(self, role, content):\n",
    "        if len(self.messages) == 0:\n",
    "            self.messages.append({\"role\": role, \"content\": content})\n",
    "        else:\n",
    "            self.messages.insert(0, {\"role\": role, \"content\": content})\n",
    "    \n",
    "    def pop_message(self):\n",
    "        if self.messages:\n",
    "            return self.messages.pop()\n",
    "        return None\n",
    "    \n",
    "    def pop_message_front(self):\n",
    "        if self.messages:\n",
    "            return self.messages.pop(0)\n",
    "        return None\n",
    "\n",
    "    def have_system_prompt(self):\n",
    "        if len(self.messages)>0:\n",
    "            return self.messages[0]['role'] == 'system'\n",
    "        return False\n",
    "    \n",
    "    def clear_messages(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def get_response(self, query, store=True):\n",
    "        if store:\n",
    "            self.add_message(\"user\",query)\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=self.messages,\n",
    "            temperature=self.temperature,\n",
    "        )\n",
    "        if store:\n",
    "            self.add_message(\"assistant\", response.choices[0].message.content)\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def get_response_vision(self, query, image_path, text_store=True, image_store=False):\n",
    "        image_url = self.img_uploader.upload_to_firebase(image_path, self.uuid)\n",
    "        # image_b64 = encode_image_to_base64(image_path)\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=self.messages[0:] + [{\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": query},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "                    ], \n",
    "                }], \n",
    "            temperature=self.temperature,\n",
    "        )\n",
    "        if image_store:\n",
    "            self.add_message(\"user\",[\n",
    "                        {\"type\": \"text\", \"text\": query},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "                    ])\n",
    "            self.add_message(\"assistant\", response.choices[0].message.content)\n",
    "        elif text_store:\n",
    "            self.add_message(\"user\", query)\n",
    "            self.add_message(\"assistant\", response.choices[0].message.content)\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "class ChefBot(LLMChatBot):\n",
    "    def __init__(self, model_name=\"gpt-4o\", temperature=0.4, key=None, uuid=None, system_prompt_path=\"ChefBotSystemPrompt.txt\"):\n",
    "        super().__init__(model_name, temperature, key, uuid)\n",
    "        self.init_system_prompt(system_prompt_path)\n",
    "\n",
    "    def init_system_prompt(self, system_prompt_path):\n",
    "        if self.have_system_prompt():\n",
    "            self.pop_message_front()\n",
    "        self.add_message_front(\"system\",open(system_prompt_path, \"r\").read())\n",
    "\n",
    "    def get_response_realtime_vision(self, query, image_path=\"vision.png\", text_store=True, image_store=False):\n",
    "        \"\"\"\n",
    "        The parameters:\n",
    "            - image_path: needed to be updated with the precise image name.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.get_response_vision(query, image_path, text_store, image_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9c63ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMChatBot is initialized with model: o4-mini\n"
     ]
    }
   ],
   "source": [
    "apikey = open(config.get_gptapi(), \"r\").read().strip()\n",
    "myuuid = open(config.get_myuuid(), \"r\").read().strip()\n",
    "MyBot = ChefBot(model_name=\"o4-mini\", temperature=1.0, key=apikey, uuid=myuuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09428082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"채소 코울슬로\",\n",
      "  \"ingredients\": \"양배추 200g, 당근 1개, 상추 3장, 마요네즈 2큰술, 소금 한 꼬집, 후추 약간\",\n",
      "  \"recipe\": [\n",
      "    \"1. 양배추 200g을 흐르는 물에 씻는다.\",\n",
      "    \"2. 양배추를 채칼로 얇게 채 썬다.\",\n",
      "    \"3. 당근 1개를 껍질을 벗기고 얇게 채 썬다.\",\n",
      "    \"4. 상추 3장을 깨끗이 씻는다.\",\n",
      "    \"5. 상추를 물기를 털고 먹기 좋은 크기로 자른다.\",\n",
      "    \"6. 볼에 채썬 양배추를 넣는다.\",\n",
      "    \"7. 볼에 채썬 당근을 넣는다.\",\n",
      "    \"8. 볼에 자른 상추를 넣는다.\",\n",
      "    \"9. 볼에 마요네즈 2큰술을 넣는다.\",\n",
      "    \"10. 볼에 소금 한 꼬집을 넣는다.\",\n",
      "    \"11. 볼에 후추 약간을 넣는다.\",\n",
      "    \"12. 볼의 재료를 젓가락이나 숟가락으로 고루 버무린다.\",\n",
      "    \"13. 완성된 코울슬로를 접시에 담는다.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(MyBot.get_response_vision(\"냉장고 내부 재료로 만들 수 있는 요리 레시피.\", \"istockphoto-1216556201-1024x1024.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "820eee36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"알리오 올리오\",\n",
      "  \"ingredients\": \"스파게티 면 200g, 올리브 오일 100ml, 마늘 6쪽, 페페론치노 2개, 소금 약간, 파슬리 약간\",\n",
      "  \"recipe\": [\n",
      "    \"1. 마늘은 얇게 슬라이스합니다.\",\n",
      "    \"2. 페페론치노는 반으로 쪼개거나 잘게 부숩니다.\",\n",
      "    \"3. 냄비에 물을 끓이고 소금을 넣은 뒤, 스파게티 면을 포장지에 적힌 시간보다 1분 짧게 삶습니다.\",\n",
      "    \"4. 면을 건져내어 물기를 빼고, 삶은 물을 한 컵 따로 보관합니다.\",\n",
      "    \"5. 팬에 올리브 오일을 두르고 중약불에서 마늘을 볶아 향을 냅니다.\",\n",
      "    \"6. 마늘이 약간 노릇해지면 페페론치노를 추가해 함께 볶습니다.\",\n",
      "    \"7. 삶은 스파게티 면을 팬에 넣고, 준비한 면수를 조금씩 추가하며 섞어줍니다.\",\n",
      "    \"8. 소금으로 간을 맞추고, 마지막으로 파슬리를 뿌려 섞습니다.\",\n",
      "    \"9. 완성된 알리오 올리오를 접시에 담아냅니다.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(MyBot.get_response(\"알리오 올리오 레시피 알려줘.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f49b782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버킷 이름: jams-f92b1.appspot.com\n"
     ]
    }
   ],
   "source": [
    "from firebase_admin import storage\n",
    "bucket = storage.bucket()\n",
    "print(\"버킷 이름:\", bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12823d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fortest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
